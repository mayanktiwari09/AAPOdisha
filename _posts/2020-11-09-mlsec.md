---
# POST EDITING GUIDELINES
# Set the URL of the page using "permalink"
# Set research topic of the page using "tagline"
# Set the title/subject of the page using "heading"
# Set the headerimg by uploading an image to /assets/images/ and adding the URL to "headerimg"

layout: post
date: 2020-09-11 16:21:00 -0700
tags: security
headerimg:
permalink: mlsec
topic: Machine Learning, Security
heading: "ML Security"
description: "We study attacks and defenses for distributed machine learning systems"
---
<!-- Project Overview section -->
<div class="container-fluid bg-gray my-5 py-5">
    <div class="container pt-4">
    <p>
Data is essential to training high quality machine learning (ML)
models. Federated learning (FL) is a distributed ML approach that aims
to facilitate collaborative ML on models from data distributed across
personal devices, without disclosing device-local training
data. Unfortunately, FLâ€™s design is susceptible to security and
privacy attacks. The client nodes play an important role in the
computation as they are maintaining their own local data, whereas
before they merely compute the gradient using the data sent out from
the server. This allows client nodes to mount a variety of attacks.
    </p>
    <p>
We have been considered systems that provide alternatives to FL, as
well as attacks and defenses for FL-based systems. For example, we
previously created FoolsGold, a defense for model poisoning attacks.
In a poisoning attack, the attacker includes bad data as part of the
client training set, which causes the trained model to make wrong
predictions on certain input classes. In our ongoing work we are
considering how an attacker may use the clients they control to hurt
the training process more generally. For example, clients that connect
and disconnect may lead to poor model quality (known as malicious node
churn). We also study how these strategies comprise existing FL
defenses against security and privacy attacks.
    </p>
    </div>
</div>
<!-- /Project Overview section -->
<!-- Project Details and Additional Info -->
<div class="container">
    <h6>Additional Information</h6>
        <ol>
            <li>People: Shiqi He</li>
            <li>FoolsGold paper: <a href="https://www.cs.ubc.ca/~bestchai/papers/foolsgold-raid2020.pdf">The Limitations of Federated Learning in Sybil Settings</a>, RAID 2020</li>
            <li>Brokered agreements paper: <a href="https://www.cs.ubc.ca/~bestchai/papers/apsys19-brokering.pdf">Brokered Agreements in Multi-Party Machine Learning</a>, APSys 2019</li>
        </ol>
</div>
<!-- /Project Details and Additional Info -->
